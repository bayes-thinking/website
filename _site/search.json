[
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Bayesian Thinking",
    "section": "",
    "text": "Topic\nNotes\nExamples\n\n\n\n\nIntroduction to Technology\n\n\n\n\nProbability\n\n\n\n\nProbability Distributions\n\n\n\n\nBayes Theorem\n\n\n\n\nDistributions: Priors\n\n\n\n\nDistributions: Data\n\n\n\n\nBeta-Binomial\n\n\n\n\nNormal-Normal\n\n\n\n\nMCMC & Gibbs Sampler\n\n\n\n\nPredictions"
  },
  {
    "objectID": "instructors/4-0-priors-lesson-plan.html",
    "href": "instructors/4-0-priors-lesson-plan.html",
    "title": "Prior Distributions",
    "section": "",
    "text": "Objective:\n\nBy the end of this lesson, students will have reviewed the following topics:\n\nDefinition of prior distribution\nDefinition of hyperparameter\nIdentify appropriate distribution to represent belief\n\n\nDuration:\n\n75 minutes\n\nMaterials:\n\nHandouts with exercises and problems related to basic probability\nComputer, projector, and screen\n\nIntroduction:\n\nWhat should the probability distribution be for the maximum temperature 1 year from today?\nWhat should the probability distribution be for the final grade in this course?\n\nIntroduce the lesson’s topic:\n\nToday we will apply our knowledge of distributions to represent our prior beliefs.\n\nMain Content:\nVocabulary\n\nPrior distribution: probability model for our prior understanding of \\(\\text{P}[\\text{event}]\\).\n\nHyperparameter: parameter in the specified prior distribution.\n\nData distribution: probability model for the outcome, \\(y\\).\n\nParameter: parameter in the specified data distribution.\n\nPosterior distribution: probability model that summarizes the plausibility of the outcome, \\(y\\), given the prior information.\n\nBeta distribution\nSuppose we are looking at binary outcomes; we want to put a prior on \\(\\pi = P[Y=1]\\), meaning \\(\\pi \\in [0, 1]\\).\nThe Beta model (often used to describe the variability in \\(\\pi\\)) has shape parameters \\(\\alpha &gt; 0\\) and \\(\\beta &gt; 0\\), and these are the shape hyperparameters.\n\\[\\pi \\sim \\text{Beta}\\left(\\alpha, \\beta \\right),\\]\nThe Beta model’s pdf is\n\\[f\\left( \\pi \\right) = \\frac{\\Gamma \\left( \\alpha + \\beta \\right)}{\\Gamma \\left( \\alpha \\right) \\Gamma \\left( \\beta \\right)} \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1},\\]\n\nNote the following:\n\n\\(\\Gamma\\left( z \\right) = \\int_{0}^{\\infty} x^{z-1} e^{-y} dx\\)\n\\(\\Gamma\\left( z + 1 \\right) = z \\Gamma\\left( z \\right)\\)\nif \\(z\\in \\mathbb{Z}^+\\), then \\(\\Gamma\\left( z \\right) = (z-1)!\\)\n\n\nNormal distribution\nSuppose we are now examining a continuous outcome. Let \\(Y\\) be a continuous random variable that can take any value in \\(\\mathbb{R}\\); i.e., \\(Y \\in \\left(-\\infty, \\infty\\right)\\).\nLet us assume that the variability in \\(Y\\) can be represented by the normal distribution with mean parameter \\(\\mu \\in \\mathbb{R}\\) and standard deviation parameter \\(\\sigma \\in \\mathbb{R}^+\\).\n\\[Y \\sim N\\left(\\mu, \\sigma^2\\right)\\]\nThe normal model’s pdf is\n\\[f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{\\left(y - \\mu\\right)^2}{2\\sigma^2} \\right\\}\\]\n\nNote: \\(\\sigma\\) provides a sense of scale for \\(Y\\); approximately 95% of \\(Y\\) values will be within 2 standard deviations.\n\ni.e., \\(\\mu \\pm 2 \\sigma\\)\n\n\nCalculation and Practice:\n\nExamples for the Beta distribution:\n\nExample 1: plotting with different parameters\nExample 2: students evaluate and choose between three distributions\nExample 3: students derive appropriate prior\n\nExamples for the normal distribution:\n\nExample 1: what happens as variability changes?\nExample 2: students construct appropriate normals with given mean\nExample 3: students derive appropriate prior\n\n\nDiscussion and Wrap-Up:\n\nFacilitate a class discussion to review the example problems, reinforce key concepts, and answer any questions the students have.\n\nHomework:\n\nAssign additional problems to practice the basic probability rules.\n\nFormative Assessment:\n\nEvaluate students based on their participation in discussions, their ability to solve example problems, and their performance on the assigned homework.\n\nConclusion:\n\nEmphasize that a prior will not make or break an analysis.\nOur goal is to analyze in the best way possible."
  },
  {
    "objectID": "instructors/7-1-normal-normal-in-class-examples.html",
    "href": "instructors/7-1-normal-normal-in-class-examples.html",
    "title": "Examples for Normal-Normal",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)"
  },
  {
    "objectID": "instructors/7-1-normal-normal-in-class-examples.html#the-normal-model",
    "href": "instructors/7-1-normal-normal-in-class-examples.html#the-normal-model",
    "title": "Examples for Normal-Normal",
    "section": "The Normal Model",
    "text": "The Normal Model\nRecall the normal model,\n\\[f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{\\left(y - \\mu\\right)^2}{2\\sigma^2} \\right\\}\\]\nwhere \\(y\\) is a continuous random variable that can take any value in \\(\\mathbb{R}\\); i.e., \\(Y \\in \\left(-\\infty, \\infty\\right)\\).\nSuppose we have \\(n\\) observations, then the joint distribution is given by\n\\[f(\\overset{\\to}{y}|\\mu) = \\prod_{i=1}^n f(y_i|\\mu) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{\\left(y_i - \\mu\\right)^2}{2\\sigma^2} \\right\\}\\]\nThen the likelihood is given by,\n\\[\n\\begin{align*}\nL(\\mu| \\overset{\\to}{y}) &\\propto \\prod_{i=1}^n \\exp\\left\\{-\\frac{\\left(y_i - \\mu\\right)^2}{2\\sigma^2} \\right\\} = \\exp\\left\\{-\\frac{\\sum_{i=1}^n \\left(y_i - \\mu\\right)^2}{2\\sigma^2} \\right\\} \\\\\n&\\propto \\exp\\left\\{-\\frac{\\left(\\bar{y} - \\mu\\right)^2}{2\\sigma^2/n} \\right\\}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "instructors/7-1-normal-normal-in-class-examples.html#the-normal-normal-model",
    "href": "instructors/7-1-normal-normal-in-class-examples.html#the-normal-normal-model",
    "title": "Examples for Normal-Normal",
    "section": "The Normal-Normal Model",
    "text": "The Normal-Normal Model\n\nLet \\(\\mu \\in (-\\infty, \\infty)\\) be an unknown mean parameter and \\((Y_1, Y_2, ..., Y_n)\\) be an independent \\(N(\\mu, \\sigma^2)\\), where \\(\\sigma\\) is assumed to be known.\nThe Normal-Normal Bayesian model has Normal distributions for both prior and data. The Normal prior is on the unknown mean, \\(\\mu\\).\n\n\\[Y_i | \\mu \\overset{\\text{ind}}{\\sim} N(\\mu, \\sigma^2)\\]\n\\[\\mu \\sim N(\\theta, \\tau^2)\\]\n\nWhen we have data \\(\\overset{\\to}{y} = (y_1, ..., y_n)\\) with mean \\(\\bar{y}\\), the posterior distribution for \\(\\mu\\) is also Normal with updated parameters,\n\n\\[\\mu|\\overset{\\to}{y} \\sim N\\left( \\theta \\frac{\\sigma^2}{n\\tau^2 + \\sigma^2} + \\bar{y} \\frac{n\\tau^2}{n\\tau^2+\\sigma^2}, \\frac{\\tau^2 \\sigma^2}{n\\tau^2 + \\sigma^2} \\right)\\]\n\nExample 1aExample 1b\n\n\n\nLet’s apply this! Consider analysis of \\(\\mu\\), the average hippocampal volume among people that have a history of concussions.\nFirst, let’s derive the prior distribution. From the textbook, we can reasonably assume that the hippocampal volumes of our \\(n=25\\) subjects, \\(\\overset{\\to}{Y_i} = (y_1, ..., y_n)\\), are independent and normally distributed around a mean volume, \\(\\mu\\), with standard deviation \\(\\sigma\\).\nWe don’t have prior information about this very specific group, however, Wikipedia tells us that among the general population of human adults, each half of the hippocampus has a volume between 3.0 and 3.5 cm3 \\(\\to\\) the total hippocampal volume of both sides of the brain is between 6 and 7 cm3.\nBecause \\(\\sigma\\) is a nuisance parameter, we’ll assume that the standard deviation is known to be \\(\\sigma=0.5\\) cm3.\nWhat is the prior distribution in mathematical notation?\nGraph the prior distribution, below:\n\n\nImport the FootballBrain data from the Lock5Data package.\n\n\nOnly include those that have a history of concussions (fb_concuss).\n\n\nWhat is the average hippocampal volume (volume) of those that have a history of concussions?\n\n\nConstruct the density plot for the hippocampal volume (volume)\n\n\nDoes the normal distribution seem reasonable to use here?\nPlot the Normal-Normal model using the plot_normal_normal() function from the bayesrules package.\n\n\nRun the summarize_normal_normal() function from the bayesrules package.\n\n\n\n\nLet’s now explore those that did not have prior concussions.\nRe-import the FootballBrain data from the Lock5Data package.\n\n\nOnly include those that do not have a history of concussions (fb_no_concuss).\n\n\nFind the average mean hippocampal volume and sample size of the control subjects who have not been diagnosed with a concussion.\n\n\nFind the posterior model of \\(\\mu\\) using summarize_normal_normal() from the bayesrules package.\n\n\nPlot the Normal-Normal model using the plot_normal_normal() function from the bayesrules package.\n\n\n\n\n\nExample 2aExample 2bExample 2cExample 2d\n\n\n\nSuppose you just bought stock in Mojo’s Bakery. Let \\(\\mu\\) be a random variable that represents the average dollar amount that your stock in Mojo’s Bakery goes up or down in a one-day period.\nYou believe that \\(\\mu=8.7\\) dollars with a standard deviation of \\(2.9\\) dollars is a reasonable starting point.\nPlot the appropriate Normal prior model for \\(\\mu\\).\n\n\nDoes it seem plausible that the stock would increase by an average of 9.1 dollars in one day?\nDoes it seem plausible that the stock would increase by an average of 5 dollars in one day?\nWhat is the prior probability that, on average, the stock price decreases?\n\n\nWhat is the prior probability that, on average, the stock price increases by more than 9.5 dollars per day?\n\n\n\n\nSuppose we assume that the daily changes in Mojo’s Bakery stock are normally distributed around an unknown mean of \\(\\mu\\) with a known standard deviation of \\(\\sigma=2\\) dollars.\nOn a random sample of 4 days, you observe changes in stock value of –0.6, 1.8, 3.9, and –4.1 dollars.\nPlot the corresponding likelihood function of \\(\\mu\\).\n\n\nPlot the Normal-Normal model using the plot_normal_normal() function from the bayesrules package.\n\n\nUse summarize_normal_normal() from the bayesrules package to calculate descriptive statistics for the prior and posterior models.\n\n\nWhat is the posterior probability that, on average, the stock price goes down?\n\n\nWhat is the posterior probability that, on average, the stock price goes up by more than 9.5 dollars per day?\n\n\n\n\nSuppose we assume that the daily changes in Mojo’s Bakery stock are normally distributed around an unknown mean of \\(\\mu\\) with a known standard deviation of \\(\\sigma=1\\) dollars.\nOn a random sample of 4 days, you observe changes in stock value of –0.6, 1.8, 3.9, and –4.1 dollars.\nPlot the corresponding likelihood function of \\(\\mu\\).\n\n\nPlot the Normal-Normal model using the plot_normal_normal() function from the bayesrules package.\n\n\nUse summarize_normal_normal() from the bayesrules package to calculate descriptive statistics for the prior and posterior models.\n\n\nWhat is the posterior probability that, on average, the stock price goes down?\n\n\nWhat is the posterior probability that, on average, the stock price goes up by more than 9.5 dollars per day?\n\n\n\n\nSuppose we assume that the daily changes in Mojo’s Bakery stock are normally distributed around an unknown mean of \\(\\mu\\) with a known standard deviation of \\(\\sigma=3\\) dollars.\nOn a random sample of 4 days, you observe changes in stock value of –0.6, 1.8, 3.9, and –4.1 dollars.\nPlot the corresponding likelihood function of \\(\\mu\\).\n\n\nPlot the Normal-Normal model using the plot_normal_normal() function from the bayesrules package.\n\n\nUse summarize_normal_normal() from the bayesrules package to calculate descriptive statistics for the prior and posterior models.\n\n\nWhat is the posterior probability that, on average, the stock price goes down?\n\n\nWhat is the posterior probability that, on average, the stock price goes up by more than 9.5 dollars per day?"
  },
  {
    "objectID": "instructors/2-0-probability-2-lesson-plan.html",
    "href": "instructors/2-0-probability-2-lesson-plan.html",
    "title": "Review of Basic Probability - Part 2",
    "section": "",
    "text": "Objective:\n\nBy the end of this lesson, students will have reviewed the following topics:\n\nIndependent/dependent events\nMultiplication Rule for independent events\nConditional probability\nGeneral Multiplication Rule for dependent events\n\n\nDuration:\n\n75 minutes\n\nMaterials:\n\nHandouts with exercises and problems related to basic probability\nComputer, projector, and screen\n\nIntroduction:\n\nExamples that can be used to jump start topic:\n\nbirthday problem\nMonty Hall problem\ncasino games\n\n\nIntroduce the lesson’s topic:\n\nToday we will continue reviewing basic probability rules.\n\nHistorical Context:\n\n1560s: Cardano wrote Liber de ludo aleae, the first known systematic treatment of probability, and as the result of a gambling addiction.\n1654: Fermat and Pascal worked on the foundation of probability theory through correspondence.\n1812 and 1814: Laplace published Théorie analytique des probabilités and Essai philosophique sur les probabilités, outlining many basic and fundamental results in statistics.\n\nMain Content:\n\nConditional probability: if \\(A\\) and \\(B\\) are any two events,\n\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(A)}\\]\n\nGeneral Multiplication Rule for dependent events: the probability that two events \\(A\\) and \\(B\\) both occur is\n\n\\[P(A \\cap B) = P(A) \\times P(A|B)\\]\n\nIndependent/dependent events: two events, \\(A\\) and \\(B\\) are independent if\n\n\\[P(A|B) = P(A) \\text{ or } P(B|A) = P(B)\\]\n\nMultiplication Rule for independent events: when two events are independent,\n\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\nDiscussion and Wrap-Up:\n\nFacilitate a class discussion to review the example problems, reinforce key concepts, and answer any questions the students have.\n\nHomework:\n\nAssign additional problems to practice the basic probability rules.\n\nFormative Assessment:\n\nEvaluate students based on their participation in discussions, their ability to solve example problems, and their performance on the assigned homework.\n\nConclusion:\n\nEmphasize these are building blocks for the next lesson and long term understanding probability."
  },
  {
    "objectID": "instructors/1-1-probability-1-in-class-examples.html",
    "href": "instructors/1-1-probability-1-in-class-examples.html",
    "title": "Examples for Review of Basic Probability - Part 1",
    "section": "",
    "text": "Events and Sample Spaces\n\nExample 1Example 2Example 3\n\n\n\nSuppose we roll two fair, indistinguishable, dice.\n\nWhat is the sample space?\nDoes order matter for the experiment? Why or why not?\nLet event \\(A\\) be rolling doubles. What are the outcomes that belong to event \\(A\\)?\nLet event \\(B\\) be rolling at least one odd number. What are the outcomes that belong to event \\(B\\)?\n\nTable of possible outcomes when rolling two fair, indistinguishable dice:\n\n\n\n\n\n\n\n\n(1, 1)\n\n\n(1, 2)\n\n\n(1, 3)\n\n\n(1, 4)\n\n\n(1, 5)\n\n\n(1, 6)\n\n\n\n\n\n\n(2, 1)\n\n\n(2, 2)\n\n\n(2, 3)\n\n\n(2, 4)\n\n\n(2, 5)\n\n\n(2, 6)\n\n\n\n\n(3, 1)\n\n\n(3, 2)\n\n\n(3, 3)\n\n\n(3, 4)\n\n\n(3, 5)\n\n\n(3, 6)\n\n\n\n\n(4, 1)\n\n\n(4, 2)\n\n\n(4, 3)\n\n\n(4, 4)\n\n\n(4, 5)\n\n\n(4, 6)\n\n\n\n\n(5, 1)\n\n\n(5, 2)\n\n\n(5, 3)\n\n\n(5, 4)\n\n\n(5, 5)\n\n\n(5, 6)\n\n\n\n\n(6, 1)\n\n\n(6, 2)\n\n\n(6, 3)\n\n\n(6, 4)\n\n\n(6, 5)\n\n\n(6, 6)\n\n\n\n\n\n\n\n\n\nConsider the word TENNESSEE. Suppose we were to randomly select a letter.\n\nWhat is the sample space?\nWhat is \\(P(T)\\)?\nWhat is \\(P(E)\\)?\nWhat is \\(P(N)\\)?\nWhat is \\(P(S)\\)?\n\n\n\n\n\nSet up: split class into various groups.\nSuppose we roll two indistinguishable fair dice. We are interested in the sum of the numbers on the two dice.\n\nWhat does the sample space become?\nDoes order matter for the experiment? Why or why not?\nLet event \\(A\\) be rolling an even sum. What are the outcomes that belong to event \\(A\\)?\n\nWhat is \\(P(A)\\)?\n\nLet event \\(B\\) be rolling a sum that is a prime number. What are the outcomes that belong to event \\(B\\)?\n\nWhat is \\(P(B)\\)?\n\nAssign each group an event and have them find the probabilities.\n\n\\(C\\): roll a sum that is an odd sum (bonus: complement rule early :))\n\\(D\\): roll a sum that is (strictly) less than 5.\n\\(E\\): roll an even sum that is 9 or greater.\netc.\n\nHave one member of each group present the set of outcomes belonging to the event.\nHave another member present how to find the probability.\n\nTable of possible outcomes:\n\n\n\n\n\n\n\n\n(1, 1) = 2\n\n\n(1, 2) = 3\n\n\n(1, 3) = 4\n\n\n(1, 4) = 5\n\n\n(1, 5) = 6\n\n\n(1, 6) = 7\n\n\n\n\n\n\n(2, 1) = 3\n\n\n(2, 2) = 4\n\n\n(2, 3) = 5\n\n\n(2, 4) = 6\n\n\n(2, 5) = 7\n\n\n(2, 6) = 8\n\n\n\n\n(3, 1) = 4\n\n\n(3, 2) = 5\n\n\n(3, 3) = 6\n\n\n(3, 4) = 7\n\n\n(3, 5) = 8\n\n\n(3, 6) = 9\n\n\n\n\n(4, 1) = 5\n\n\n(4, 2) = 6\n\n\n(4, 3) = 7\n\n\n(4, 4) = 8\n\n\n(4, 5) = 9\n\n\n(4, 6) = 10\n\n\n\n\n(5, 1) = 6\n\n\n(5, 2) = 7\n\n\n(5, 3) = 8\n\n\n(5, 4) = 9\n\n\n(5, 5) = 10\n\n\n(5, 6) = 11\n\n\n\n\n(6, 1) = 7\n\n\n(6, 2) = 8\n\n\n(6, 3) = 9\n\n\n(6, 4) = 10\n\n\n(6, 5) = 11\n\n\n(6, 6) = 12\n\n\n\n\n\n\n\n\n\n\n\nAddition Rule for Mutually Exclusive Events\n\nExample 1Example 2Example 3\n\n\n\nSuppose a single card is drawn from a standard 52-card deck.\n\nWhat is the sample space?\n\nSuppose event \\(A\\) is drawing a face card (J, Q, K).\n\nWhat is \\(P(A)\\)?\n\nSuppose event \\(B\\) is drawing a black, even card.\n\nWhat is \\(P(B)\\)?\n\nAre \\(A\\) and \\(B\\) mutually exclusive events? Why or why not?\n\nWhat is \\(P(A \\cup B)\\)?\n\n\nTable of card deck:\n\n\n\n\n\n\n\nClubs:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\n\n\nSpades:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\nDiamonds:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\nHearts:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\n\n\n\n\n\nSuppose we toss three coins.\n\nWhat is the sample space?\n\nLet event \\(A\\) be flipping at least two tails.\n\nWhat is \\(P(A)\\)?\n\nLet event \\(B\\) be flipping no tails.\n\nWhat is \\(P(B)\\)?\n\nLet event \\(C\\) be flipping no heads.\n\nWhat is \\(P(C)\\)?\n\nAre the following events mutually exclusive? Why or why not?\n\n\\(A\\) and \\(B\\)\n\\(A\\) and \\(C\\)\n\\(B\\) and \\(C\\)\n\n\nSample Space:\n\n\n\n\n\n\n\nHHH\n\n\n\n\n\n\n\n\n\n\nHHT\n\n\nHTH\n\n\nTHH\n\n\n\n\nHTT\n\n\nTHT\n\n\nTTH\n\n\n\n\nTTT\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet up: split class into various groups.\nSuppose we are rolling two dice: one red, one blue.\nAssign each group an event and have them find the probabilities:\n\n\\(A\\): Rolling a red 2.\n\\(B\\): Rolling a blue 5.\n\\(C\\): Rolling a red odd.\n\\(D\\): Rolling a sum that is odd.\n\\(E\\): Rolling a sum that is even.\netc.\n\nHave groups determine which other groups they are mutually exclusive with.\nHave groups find other groups they are mutually exclusive with and find \\(P(E_1 \\cup E_2)\\).\n\n\n\n\n\n\nExamples for the General Addition Rule\n\nExample 1Example 2Example 3Example 4\n\n\n\nThe probability of a teenager owning a Playstation is 0.31, of owning a Switch is 0.56 and of owning both is 0.17.\n\nWhat are the events that are defined by the problem?\n\nIf a teenager is chosen at random, what is the probability that the teenager owns a Playstation or Switch?\n\nWhat is \\(P(\\text{Playstation})\\)?\nWhat is \\(P(\\text{Switch})\\)?\nWhat is \\(P(\\text{Playstation} \\cap \\text{Switch})\\)?\nWhat is \\(P(\\text{Playstation} \\cup \\text{Switch})\\)?\n\nSuggestion: Venn Diagram\n\n\n\n\nThere are 100 students taking either STA4173 (Biostatistics) or STA4231 (Statistics for Data Science I). 80 students are taking Biostatistics and 30 students are taking Statistics for Data Science I.\n\nWhat is \\(P(\\text{Biostatistics})\\)?\nWhat is \\(P(\\text{Statistics for Data Science I})\\)?\nWhat is \\(P(\\text{Biostatistics} \\cap \\text{Statistics for Data Science I})\\)?\nWhat is \\(P(\\text{Biostatistics} \\cup \\text{Statistics for Data Science I})\\)?\n\nSuggestion: Venn Diagram\n\n\n\n\nSuppose a single card is drawn from a standard 52-card deck.\n\nWhat is the sample space?\n\nSuppose event \\(A\\) is drawing a face card (J, Q, K).\n\nWhat is \\(P(A)\\)?\n\nSuppose event \\(B\\) is drawing a red card.\n\nWhat is \\(P(B)\\)?\n\nAre \\(A\\) and \\(B\\) mutually exclusive events? Why or why not?\nWhat is \\(P(A \\cup B)\\)?\n\nTable of card deck:\n\n\n\n\n\n\n\nClubs:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\n\n\nSpades:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\nDiamonds:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\nHearts:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\n\n\n\n\n\nSet up: split class into various groups.\nSuppose two cards are drawn without replacement from a standard 52-card deck.\nAssign each group an event and have them find the corresponding probabilities.\n\n\\(A\\): drawing two even cards\n\\(B\\): drawing two face cards\n\\(C\\): drawing a red 2 and black 3\netc.\n\nHave one student from each group present their probabilities.\nPair groups together and ask them to find \\(P(E_1 \\cup E_2)\\).\nHave one student from each paired group present their solution.\n\nTable of card deck:\n\n\n\n\n\n\n\nClubs:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\n\n\nSpades:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\nDiamonds:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK\n\n\n\n\nHearts:\n\n\nA\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\nJ\n\n\nQ\n\n\nK"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Thinking",
    "section": "",
    "text": "Topic\nNotes\nExamples\n\n\n\n\nIntroduction to Technology\n\n\n\n\nProbability\npart 1 lesson plan, part 2 lesson plan\n\n\n\nProbability Distributions\n\n\n\n\nBayes Theorem\n\n\n\n\nDistributions: Priors\nlesson plan\n\n\n\nDistributions: Data\n\n\n\n\nBeta-Binomial\n\n\n\n\nNormal-Normal\nlesson plan\n\n\n\nMCMC\n\n\n\n\nGibbs Sampler\n\n\n\n\nPredictions"
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Bayesian Thinking",
    "section": "",
    "text": "Topic\nNotes\nExamples\n\n\n\n\nIntroduction to Technology\n\n\n\n\nProbability\n\n\n\n\nProbability Distributions\n\n\n\n\nBayes Theorem\n\n\n\n\nDistributions: Priors\n\n\n\n\nDistributions: Data\n\n\n\n\nBeta-Binomial\n\n\n\n\nNormal-Normal\n\n\n\n\nMCMC & Gibbs Sampler\n\n\n\n\nPredictions"
  },
  {
    "objectID": "instructors/4-1-priors-in-class-examples.html",
    "href": "instructors/4-1-priors-in-class-examples.html",
    "title": "Examples for Prior Distributions",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)"
  },
  {
    "objectID": "instructors/4-1-priors-in-class-examples.html#language-notes-about-nomenclature",
    "href": "instructors/4-1-priors-in-class-examples.html#language-notes-about-nomenclature",
    "title": "Examples for Prior Distributions",
    "section": "Language / notes about nomenclature",
    "text": "Language / notes about nomenclature"
  },
  {
    "objectID": "instructors/4-1-priors-in-class-examples.html#beta-prior",
    "href": "instructors/4-1-priors-in-class-examples.html#beta-prior",
    "title": "Examples for Prior Distributions",
    "section": "Beta Prior",
    "text": "Beta Prior\n\nReview the beta distribution\nSuppose we are looking at binary outcomes; we want to put a prior on \\(\\pi = P[Y=1]\\), meaning \\(\\pi \\in [0, 1]\\).\nThe Beta model (often used to describe the variability in \\(\\pi\\)) has shape parameters \\(\\alpha &gt; 0\\) and \\(\\beta &gt; 0\\), and these are the shape hyperparameters.\n\\[\\pi \\sim \\text{Beta}\\left(\\alpha, \\beta \\right),\\]\nThe Beta model’s pdf is\n\\[f\\left( \\pi \\right) = \\frac{\\Gamma \\left( \\alpha + \\beta \\right)}{\\Gamma \\left( \\alpha \\right) \\Gamma \\left( \\beta \\right)} \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1},\\]\n\nNote the following:\n\n\\(\\Gamma\\left( z \\right) = \\int_{0}^{\\infty} x^{z-1} e^{-y} dx\\)\n\\(\\Gamma\\left( z + 1 \\right) = z \\Gamma\\left( z \\right)\\)\nif \\(z\\in \\mathbb{Z}^+\\), then \\(\\Gamma\\left( z \\right) = (z-1)!\\)\n\n\n\nExample 1Example 2Example 3\n\n\nLet’s play with plotting the Beta distribution.\n\nplot_beta(5, 5)\n\n\n\nplot_beta(15, 15)\n\n\n\nplot_beta(30, 30)\n\n\n\nplot_beta(2, 5)\n\n\n\nplot_beta(5, 2)\n\n\n\nplot_beta(2,1)\n\n\n\n\n\n\nJillian is a soccer player who, throughout her career in competitive soccer, has probability 0.5 of scoring when she attempts. However, her coach suspects that she’s getting better. Her coach begins keeping tabs and is going to ask us to analyze the data. While we wait for them to complete data collection, we can go ahead and decide on the prior distribution.\nThinking about our original exploration of the Beta distribution,\n\nplot_beta(5, 5)\n\n\n\nplot_beta(15, 15)\n\n\n\nplot_beta(30, 30)\n\n\n\n\nThe above distributions are centered at 0.5, we just need to decide on which is best for our analysis. What should we choose?\n\n\nSuppose we are estimating the population proportion of children with vanishing white matter disease, a rare disease. What should our prior be?"
  },
  {
    "objectID": "instructors/4-1-priors-in-class-examples.html#normal-prior",
    "href": "instructors/4-1-priors-in-class-examples.html#normal-prior",
    "title": "Examples for Prior Distributions",
    "section": "Normal Prior",
    "text": "Normal Prior\n\nReview the normal distribution\nSuppose we are now examining a continuous outcome. Let \\(Y\\) be a continuous random variable that can take any value in \\(\\mathbb{R}\\); i.e., \\(Y \\in \\left(-\\infty, \\infty\\right)\\).\nLet us assume that the variability in \\(Y\\) can be represented by the normal distribution with mean parameter \\(\\mu \\in \\mathbb{R}\\) and standard deviation parameter \\(\\sigma \\in \\mathbb{R}^+\\).\n\\[Y \\sim N\\left(\\mu, \\sigma^2\\right)\\]\nThe normal model’s pdf is\n\\[f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{\\left(y - \\mu\\right)^2}{2\\sigma^2} \\right\\}\\]\n\nNote: \\(\\sigma\\) provides a sense of scale for \\(Y\\); approximately 95% of \\(Y\\) values will be within 2 standard deviations.\n\ni.e., \\(\\mu \\pm 2 \\sigma\\)\n\n\n\nExample 1Example 2Example 3\n\n\nWhat happens as variability increases?\n\nplot_normal(0, 1) + ylim(0,0.5)\n\n\n\nplot_normal(0, 10) + ylim(0,0.5)\n\n\n\nplot_normal(0, 100) + ylim(0,0.5)\n\n\n\n\nWhat happens as variability decreases?\n\nplot_normal(0, 1) + ylim(0, 1)\n\n\n\nplot_normal(0, 0.75) + ylim(0, 1)\n\n\n\nplot_normal(0, 0.5) + ylim(0, 1)\n\n\n\n\n\n\nA new Introduction to Biostatistics instructor believes that exam grades should follow a normal distribution. Construct the following priors; remember to keep the y-axis on the same scale for all graphs.\nA prior with \\(\\mu=75\\) and high variability:\nA prior with \\(\\mu=75\\) and medium variability:\nA prior with \\(\\mu=75\\) and low variability:\n\n\nLet \\(\\mu\\) be the average 5 p.m. temperature in Pensacola. Dr. Seals believes that Pensacola is hot year round, so she believes that the average temperature is probably around 85 degrees Fahrenheit. However, you are skeptical that it is hot all year, so let’s come up with a prior for this."
  },
  {
    "objectID": "instructors/7-0-normal-normal-lesson-plan.html",
    "href": "instructors/7-0-normal-normal-lesson-plan.html",
    "title": "Normal-Normal Model",
    "section": "",
    "text": "Objective:\n\nBy the end of this lesson, students will have reviewed the following topics:\n\nWhen to implement the normal-normal model\nHow to implement the normal-normal model\nHow to disseminate analysis results\n\n\nDuration:\n\n75 minutes\n\nMaterials:\n\nHandouts with exercises and problems related to basic probability\nComputer, projector, and screen\n\nIntroduction:\nIntroduce the lesson’s topic:\nMain Content:\n\nThe Normal Model\nRecall the normal model,\n\\[f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{\\left(y - \\mu\\right)^2}{2\\sigma^2} \\right\\}\\]\nwhere \\(y\\) is a continuous random variable that can take any value in \\(\\mathbb{R}\\); i.e., \\(Y \\in \\left(-\\infty, \\infty\\right)\\).\nSuppose we have \\(n\\) observations, then the joint distribution is given by\n\\[f(\\overset{\\to}{y}|\\mu) = \\prod_{i=1}^n f(y_i|\\mu) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{\\left(y_i - \\mu\\right)^2}{2\\sigma^2} \\right\\}\\]\nThen the likelihood is given by,\n\\[\n\\begin{align*}\nL(\\mu| \\overset{\\to}{y}) &\\propto \\prod_{i=1}^n \\exp\\left\\{-\\frac{\\left(y_i - \\mu\\right)^2}{2\\sigma^2} \\right\\} = \\exp\\left\\{-\\frac{\\sum_{i=1}^n \\left(y_i - \\mu\\right)^2}{2\\sigma^2} \\right\\} \\\\\n&\\propto \\exp\\left\\{-\\frac{\\left(\\bar{y} - \\mu\\right)^2}{2\\sigma^2/n} \\right\\}\n\\end{align*}\n\\]\n\n\nThe Normal-Normal Model\n\nLet \\(\\mu \\in (-\\infty, \\infty)\\) be an unknown mean parameter and \\((Y_1, Y_2, ..., Y_n)\\) be an independent \\(N(\\mu, \\sigma^2)\\), where \\(\\sigma\\) is assumed to be known.\nThe Normal-Normal Bayesian model has Normal distributions for both prior and data. The Normal prior is on the unknown mean, \\(\\mu\\).\n\n\\[Y_i | \\mu \\overset{\\text{ind}}{\\sim} N(\\mu, \\sigma^2)\\]\n\\[\\mu \\sim N(\\theta, \\tau^2)\\]\n\nWhen we have data \\(\\overset{\\to}{y} = (y_1, ..., y_n)\\) with mean \\(\\bar{y}\\), the posterior distribution for \\(\\mu\\) is also Normal with updated parameters,\n\n\\[\\mu|\\overset{\\to}{y} \\sim N\\left( \\theta \\frac{\\sigma^2}{n\\tau^2 + \\sigma^2} + \\bar{y} \\frac{n\\tau^2}{n\\tau^2+\\sigma^2}, \\frac{\\tau^2 \\sigma^2}{n\\tau^2 + \\sigma^2} \\right)\\]\nCalculation and Practice:\n\nExample 1: concussions\nExample 2: stock prices\n\nDiscussion and Wrap-Up:\n\nFacilitate a class discussion to review the example problems, reinforce key concepts, and answer any questions the students have.\n\nHomework:\n\nAssign additional problems to practice the basic probability rules.\n\nFormative Assessment:\n\nEvaluate students based on their participation in discussions, their ability to solve example problems, and their performance on the assigned homework.\n\nConclusion:\n\nOur goal is to analyze in the best way possible."
  },
  {
    "objectID": "instructors/2-1-probability-2-in-class-examples.html",
    "href": "instructors/2-1-probability-2-in-class-examples.html",
    "title": "Examples for Review of Basic Probability - Part 2",
    "section": "",
    "text": "Conditional Probability\n\nExample 1Example 2Example 3\n\n\nIn a recent survey, a random sample of adult Americans (18+) was asked, “How likely are you to trust a news report from American media, such as MSNBC or Fox News?”\n[contingency table here]\n\nWhat is the probability that a randomly selected individual is 55+ years of age given that they are more likely to trust the news report?\nWhat is the probability that a randomly selected individual is more likely to trust the news report given that they are 55+ years of age?\n\n\n\n\n\n\nSet up: separate class into groups.\nMammograms are used to detect breast cancer. Suppose a mammogram is known to be 80% accurate. Further, suppose that in the United States, 50 million women are tested for breast cancer with mammograms and, of those tested, 250,000 have breast cancer (regardless of the results of the mammogram). Finally, the probability of a false positive is 0.07.\n\nWhat is the mathematical representation of suppose a mammogram is known to be 80% accurate?\nWhat is the mathematical representation of probability of a false positive is 0.07?\nUsing the information given, construct the contingency table for mammogram \\(\\times\\) cancer diagnosis.\n\n\n\n\n\n\nIndependent Events\n\nExample 1Example 2Example 3\n\n\nThe probability that a randomly selected person in the United States earns more than $100,000 per year is 0.179.\nThe probability that a randomly selected person in the United States earns more than $100,000 per year given that they have earned a bachelor’s degree is 0.371.\nAre these two events independent?\n\n\n\n\n\n\n\n\n\n\n\nMultiplication Rule for Independent Events\n\nExample 1Example 2Example 3"
  },
  {
    "objectID": "instructors/1-0-probability-1-lesson-plan.html",
    "href": "instructors/1-0-probability-1-lesson-plan.html",
    "title": "Review of Basic Probability - Part 1",
    "section": "",
    "text": "Objective:\n\nBy the end of this lesson, students will have reviewed the following topics:\n\nDefinition of events\nDefinition of sample space\nDefinition of probability\nLaw of Large Numbers\nAddition Rule for mutually exclusive events\nGeneral Addition Rule\nComplement Rule\n\n\nDuration:\n\n75 minutes\n\nMaterials:\n\nHandouts with exercises and problems related to basic probability\nComputer, projector, and screen\n\nIntroduction:\n\nExamples that can be used to jump start topic:\n\nbirthday problem\nMonty Hall problem\ncasino games\n\n\nIntroduce the lesson’s topic:\n\nToday we will review basic probability rules.\n\nHistorical Context:\n\n1560s: Cardano wrote Liber de ludo aleae, the first known systematic treatment of probability, and as the result of a gambling addiction.\n1654: Fermat and Pascal worked on the foundation of probability theory through correspondence.\n1812 and 1814: Laplace published Théorie analytique des probabilités and Essai philosophique sur les probabilités, outlining many basic and fundamental results in statistics.\n\nMain Content:\n\nReview of Events, Sample Spaces, and Probability:\n\nProbability: a number between 0 and 1 that measures the uncertainty of a particular event.\n\n\\(p = 0 \\to\\) event will never happen.\n\\(p = 1 \\to\\) event will definitely happen.\n\nIntuitive probability:\n\nWhat is the probability of being pulled over while speeding in Gulf Breeze?\nWhat is the probability of seeing a penguin walk around UWF?\nWhat is the probability of seeing an armadillo walk around UWF?\n\nEvents: an outcome (or collection of outcomes) in a statistical experiment\n\nEvents can be defined and described in three ways (1.7 in Albert and Hu):\n\n\\(A \\cap B\\) is the intersection between \\(A\\) and \\(B\\); it is the event that both \\(A\\) and \\(B\\) occur.\n\\(A \\cup B\\) is the union between \\(A\\) and \\(B\\); it is the event that either \\(A\\) or \\(B\\) occur.\n\\(A^c\\) is the complement of \\(A\\); it is the event that \\(A\\) does not occur.\n\n\nSample spaces: all possible outcomes of a statistical experiment\n\nAddition Rules\n\nMutually exclusive events: events that have no outcomes in common; also known as disjoint\n\nVenn Diagram examples\n\nAddition Rule for Mutually Exclusive Events: if \\(A\\) and \\(B\\) are mutually exclusive events, then \\[P(A \\cup B) = P(A) + P(B)\\]\n\nExamples: 1 instructor works through, 2 students work through\n\nGeneral Addition Rule: regardless of \\(A\\) and \\(B\\) being mutually exclusive events, \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\nExamples: 1 instructor works through, 2 students work through\n\nComplements: if \\(S\\) is the sample space, then the complement of event \\(A\\), denoted by \\(A^c\\) is all outcomes in \\(S\\) that are not outcomes in event \\(A\\).\nComplement Rule: consider any event \\(A\\) and its complement, \\(A^c\\). From probability rules, we know \\[P(A^c) = 1 - P(A)\\]\n\nExamples: 1 the instructor works through, 2 students work through\n\n\n\nCalculation and Practice:\n\nExamples for events and sample spaces:\n\nExample 1:\nExample 2:\nExample 3:\n\nExamples for the Addition Rule for Mutually Exclusive Events:\n\nExample 1\nExample 2\nExample 3\n\nExamples for the General Addition Rule:\n\nExample 1\nExample 2\nExample 3\n\n\nDiscussion and Wrap-Up:\n\nFacilitate a class discussion to review the example problems, reinforce key concepts, and answer any questions the students have.\n\nHomework:\n\nAssign additional problems to practice the basic probability rules.\n\nFormative Assessment:\n\nEvaluate students based on their participation in discussions, their ability to solve example problems, and their performance on the assigned homework.\n\nConclusion:\n\nEmphasize these are building blocks for the next lesson and long term understanding probability."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian Thinking",
    "section": "",
    "text": "This website is intended to help instructors introduce their students to Bayesian thinking."
  },
  {
    "objectID": "about.html#about-this-site",
    "href": "about.html#about-this-site",
    "title": "Bayesian Thinking",
    "section": "",
    "text": "This website is intended to help instructors introduce their students to Bayesian thinking."
  },
  {
    "objectID": "about.html#about-the-authors",
    "href": "about.html#about-the-authors",
    "title": "Bayesian Thinking",
    "section": "About the Authors",
    "text": "About the Authors\nDr. Abraham Ayebo is an Associate Professor in the Center for Learning Innovation at the University of Minnesota Rochester. He can be reached at aayebo at r dot umn dot edu.\nDr. Samantha Seals is an Associate Professor of Statistics in the Department of Mathematics and Statistics at the University of West Florida. Dr. Seals teaches upper-division and graduate statistics, biostatistics, and data science courses. She can be reached at sseals at uwf dot edu.\nDr. Toni Sorrell is an Associate Professor of Math Education in the Department of Mathematics and Computer Science Department at Longwood University. She can be reached at sorrelltp at longwood dot edu."
  },
  {
    "objectID": "about.html#funding",
    "href": "about.html#funding",
    "title": "Bayesian Thinking",
    "section": "Funding",
    "text": "Funding\nThis work is the result of the authors’ participation in the BATS program, which is supported by NSF IUSE: EHR program with award numbers 2215879, 2215920, and 2215709."
  }
]